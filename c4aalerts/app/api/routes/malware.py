"""
Malware analysis API endpoints.
"""

from typing import Any, Dict
from fastapi import APIRouter, HTTPException, Body
from pydantic import BaseModel

from c4aalerts.app.services.malware_detector import malware_detector
from c4aalerts.app.workers.queue import celery_app
from c4aalerts.app.workers.jobs import process_alert_pipeline
from c4aalerts.app.security.input_validation import validate_and_sanitize_input

router = APIRouter()


class MalwareAnalysisRequest(BaseModel):
    """Request model for malware analysis."""
    content: str = Body(..., description="Content to analyze (script, code, etc.)")
    source: str = Body("unknown", description="Source of the content")
    filename: str = Body("", description="Original filename if applicable")
    url: str = Body("", description="URL where content was found")
    user_agent: str = Body("", description="User agent of the request")
    ip_address: str = Body("", description="IP address of the source")


class MalwareAnalysisResponse(BaseModel):
    """Response model for malware analysis."""
    status: str
    message: str
    analysis_results: Dict[str, Any]
    alert_created: bool
    alert_id: str | None = None
    timestamp: str


@router.post("/analyze", response_model=MalwareAnalysisResponse)
async def analyze_malware(request: MalwareAnalysisRequest) -> MalwareAnalysisResponse:
    """
    Analyze content for malware patterns.

    This endpoint analyzes scripts, code, or other content for malicious patterns
    including payload downloaders, droppers, and evasion techniques.
    """
    try:
        # Validar y sanitizar entrada
        content_validation = validate_and_sanitize_input(request.content, "string", max_length=10000)
        if not content_validation.is_valid:
            raise HTTPException(
                status_code=400,
                detail=f"Contenido inválido: {'; '.join(content_validation.errors)}"
            )

        source_validation = validate_and_sanitize_input(request.source, "string", max_length=100)
        if not source_validation.is_valid:
            raise HTTPException(
                status_code=400,
                detail=f"Fuente inválida: {'; '.join(source_validation.errors)}"
            )

        # Perform malware analysis
        analysis_results = malware_detector.analyze_content(
            content=content_validation.sanitized_value,
            source=source_validation.sanitized_value
        )

        alert_created = False
        alert_id = None

        # If malware is detected, create an alert
        if analysis_results["detected_malware"]:
            alert = malware_detector.create_malware_alert(
                content=request.content,
                source=request.source,
                analysis_results=analysis_results
            )

            # Queue the alert for processing
            task = process_alert_pipeline.delay(alert.dict())
            alert_created = True
            alert_id = task.id

        return MalwareAnalysisResponse(
            status="success",
            message="Analysis completed successfully",
            analysis_results=analysis_results,
            alert_created=alert_created,
            alert_id=alert_id,
            timestamp=analysis_results.get("timestamp", "")
        )

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error during malware analysis: {str(e)}"
        )


@router.get("/rules")
async def get_detection_rules() -> Dict[str, Any]:
    """
    Get all available malware detection rules.

    Returns information about all detection rules including patterns,
    severity levels, and MITRE ATT&CK techniques.
    """
    rules_info = []

    for rule in malware_detector.detection_rules:
        rules_info.append({
            "name": rule.name,
            "description": rule.description,
            "severity": rule.severity.value,
            "confidence": rule.confidence,
            "techniques": [tech.value for tech in rule.techniques],
            "tags": rule.tags
        })

    return {
        "status": "success",
        "total_rules": len(rules_info),
        "rules": rules_info
    }


@router.get("/patterns")
async def get_evasion_patterns() -> Dict[str, Any]:
    """
    Get all evasion patterns that are monitored.

    Returns information about evasion techniques and suspicious commands
    that are detected by the system.
    """
    return {
        "status": "success",
        "evasion_patterns": list(malware_detector.evasion_patterns.keys()),
        "suspicious_commands": malware_detector.suspicious_commands
    }


@router.post("/test")
async def test_detection_rules(content: str = Body(..., embed=True)) -> Dict[str, Any]:
    """
    Test detection rules against provided content.

    This endpoint allows testing of detection rules without creating alerts.
    Useful for development and testing purposes.
    """
    try:
        # Perform analysis without creating alerts
        analysis_results = malware_detector.analyze_content(
            content=content,
            source="test"
        )

        return {
            "status": "success",
            "message": "Test analysis completed",
            "analysis_results": analysis_results,
            "content_length": len(content),
            "detection_summary": {
                "malware_detected": analysis_results["detected_malware"],
                "malware_family": analysis_results["malware_family"].value,
                "severity": analysis_results["severity"].value,
                "confidence": analysis_results["confidence_score"],
                "rules_triggered": len(analysis_results["detection_rules"]),
                "evasion_techniques": len(analysis_results["evasion_techniques"]),
                "suspicious_commands": len(analysis_results["suspicious_commands"])
            }
        }

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Error during test analysis: {str(e)}"
        )
