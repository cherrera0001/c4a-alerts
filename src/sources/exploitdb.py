import logging
import requests
from bs4 import BeautifulSoup

EXPLOITDB_URL = "https://www.exploit-db.com/"
BASE_LIST_URL = "https://www.exploit-db.com/?order_by=date&order=desc"

HEADERS = {
    "User-Agent": "c4a-alerts-bot/1.0"
}

def fetch_exploitdb_alerts(limit=5):
    """
    Realiza scraping sobre el sitio principal de Exploit-DB para obtener los exploits recientes.
    Retorna una lista de diccionarios con título y enlace.
    """
    try:
        response = requests.get(BASE_LIST_URL, headers=HEADERS, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        alerts = []
        table_rows = soup.select("table#exploits-table tbody tr")
        for row in table_rows:
            cols = row.find_all("td")
            if len(cols) < 2:
                continue

            exploit_id = cols[0].text.strip()
            title = cols[1].text.strip()
            href = cols[1].find("a")
            link = f"{EXPLOITDB_URL}{href['href']}" if href else EXPLOITDB_URL

            alerts.append({
                "title": title,
                "url": link,
                "source": "ExploitDB"
            })

            if len(alerts) >= limit:
                break

        return alerts

    except Exception as e:
        logging.error(f"❌ Error al consultar Exploit-DB: {e}")
        return []
